{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_transform_standard = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale()\n",
    "        # transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(\"train_dataset_lpd_filtered_3\", transform=train_transform_standard)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Pretty good discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.n = 32\n",
    "        self.main = nn.Sequential(\n",
    "            # BATCH x 128 x 128\n",
    "            nn.Conv2d(in_channels=1, out_channels=self.n, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # BATCH x 64 x 64\n",
    "            nn.Conv2d(in_channels=self.n, out_channels=self.n * 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # BATCH x 32 x 32\n",
    "            nn.Conv2d(in_channels=self.n * 2, out_channels=self.n * 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # BATCH x 16 x 16\n",
    "            nn.Conv2d(in_channels=self.n * 4, out_channels=self.n * 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # BATCH x 8 x 8\n",
    "            nn.Conv2d(in_channels=self.n * 8, out_channels=self.n * 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # BATCH x 4 x 4\n",
    "            nn.Conv2d(in_channels=self.n * 16, out_channels=1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "\n",
    "            # BATCH x 2 x 2\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return super().__str__() + \"\\nTrainable parameters: {}\".format(params)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.n = 512\n",
    "        self.main = nn.Sequential(\n",
    "            # Batch_size x n x kernel_size x kernel_size -> Batch_size x n x 4 x 4\n",
    "            nn.ConvTranspose2d(in_channels=latent_dim, out_channels=self.n, kernel_size=(4, 4), bias=False),\n",
    "            nn.BatchNorm2d(self.n),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # -> Batch_size x n x 8 x 8\n",
    "            nn.ConvTranspose2d(in_channels=self.n, out_channels=self.n // 2, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n // 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # -> Batch_size x n x 16 x 16\n",
    "            nn.ConvTranspose2d(in_channels=self.n // 2, out_channels=self.n // 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n // 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # -> Batch_size x n x 32 x 32\n",
    "            nn.ConvTranspose2d(in_channels=self.n // 4, out_channels=self.n // 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n // 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # -> Batch_size x n x 64 x 64\n",
    "            nn.ConvTranspose2d(in_channels=self.n // 8, out_channels=self.n // 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(self.n // 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # -> Batch_size x n x 128 x 128\n",
    "            nn.ConvTranspose2d(in_channels=self.n // 16, out_channels=1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        return super().__str__() + \"\\nTrainable parameters: {}\".format(params)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "fixed_noise = torch.randn(128, latent_dim, 1, 1, device=device)\n",
    "\n",
    "# Models\n",
    "generator = Generator(latent_dim=latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "generator = torch.load('generator.pt', map_location=device)\n",
    "discriminator = torch.load('discriminator.pt', map_location=device)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# loss\n",
    "criterion = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (15): ConvTranspose2d(32, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 3606976\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (12): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (15): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): Flatten(start_dim=1, end_dim=-1)\n",
      "    (17): Linear(in_features=4, out_features=1, bias=True)\n",
      "    (18): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 2795973\n"
     ]
    }
   ],
   "source": [
    "print(generator)\n",
    "print(discriminator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_12936/3961380425.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m     \u001B[0mdiscriminator_fake_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mdiscriminator_real_acc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m         \u001B[1;31m############################\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[1;31m# (1) Update Discriminator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    357\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    358\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 359\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    360\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    361\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    303\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    304\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcheck_worker_number_rationality\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 305\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0m_MultiProcessingDataLoaderIter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    306\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    307\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m    916\u001B[0m             \u001B[1;31m#     before it starts, and __del__ tries to join but will get:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m             \u001B[1;31m#     AssertionError: can only join a started process.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 918\u001B[1;33m             \u001B[0mw\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    919\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_index_queues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_queue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    920\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_workers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\process.py\u001B[0m in \u001B[0;36mstart\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    119\u001B[0m                \u001B[1;34m'daemonic processes are not allowed to have children'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    120\u001B[0m         \u001B[0m_cleanup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 121\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    122\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sentinel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_popen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msentinel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    123\u001B[0m         \u001B[1;31m# Avoid a refcycle if the target function holds an indirect\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 224\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_default_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mProcess\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    225\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mDefaultContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\context.py\u001B[0m in \u001B[0;36m_Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    325\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0m_Popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    326\u001B[0m             \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mpopen_spawn_win32\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 327\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    328\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m     \u001B[1;32mclass\u001B[0m \u001B[0mSpawnContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBaseContext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     91\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     92\u001B[0m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprep_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 93\u001B[1;33m                 \u001B[0mreduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_obj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_child\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     94\u001B[0m             \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     95\u001B[0m                 \u001B[0mset_spawning_popen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\reduction.py\u001B[0m in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 60\u001B[1;33m     \u001B[0mForkingPickler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprotocol\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdump\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     61\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_info = [0, 2, 5, 10, 20, 40, 60, 100, 140, 180, 250, 300, 350, 399]\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "num_epochs = 400\n",
    "for epoch in range(num_epochs):\n",
    "    discriminator_fake_acc = []\n",
    "    discriminator_real_acc = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        ############################\n",
    "        # (1) Update Discriminator\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        # Format batch\n",
    "        real_images = data[0].to(device)\n",
    "        b_size = real_images.size(0)\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device) # Setting labels for real images\n",
    "        # Forward pass real batch through D\n",
    "        output = discriminator(real_images).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        error_discriminator_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        error_discriminator_real.backward()\n",
    "        discriminator_real_acc.append(output.mean().item())\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, latent_dim, 1, 1, device=device)\n",
    "        # Generate fake image batch with Generator\n",
    "        fake_images = generator(noise)\n",
    "        # fake_images = modify_generator_pictures(fake_images)\n",
    "        label_fake = torch.zeros((b_size,), dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with Discriminator\n",
    "        output = discriminator(fake_images.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        error_discriminator_fake = criterion(output, label_fake)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        error_discriminator_fake.backward()\n",
    "        discriminator_fake_acc.append(output.mean().item())\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        error_discriminator = error_discriminator_real + error_discriminator_fake\n",
    "        # Update D\n",
    "        discriminator_optimizer.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update Generator\n",
    "        ###########################\n",
    "        generator_optimizer.zero_grad()\n",
    "        label = torch.ones((b_size,), dtype=torch.float, device=device)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = discriminator(fake_images).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        error_generator = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        error_generator.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        # Output training stats\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(error_generator.item())\n",
    "        D_losses.append(error_discriminator.item())\n",
    "    print(f\"Epoch: {epoch}, discrimiantor fake error: {np.mean(discriminator_fake_acc):.3}, discriminator real acc: {np.mean(discriminator_real_acc):.3}\")\n",
    "    if epoch in epoch_info:\n",
    "        with torch.no_grad():\n",
    "            fake = generator(fixed_noise).detach().cpu()\n",
    "        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(generator, 'generator.pt')\n",
    "torch.save(discriminator, 'discriminator.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=250, repeat_delay=250, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from music21 import instrument, note, chord, stream\n",
    "\n",
    "lowerBoundNote = 21\n",
    "def column2notes(column):\n",
    "    notes = []\n",
    "    for i in range(len(column)):\n",
    "        if column[i] > 255/2:\n",
    "            notes.append(i+lowerBoundNote)\n",
    "    return notes\n",
    "\n",
    "resolution = 0.1\n",
    "def updateNotes(newNotes,prevNotes):\n",
    "    res = {}\n",
    "    for note in newNotes:\n",
    "        if note in prevNotes:\n",
    "            res[note] = prevNotes[note] + resolution\n",
    "        else:\n",
    "            res[note] = resolution\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def image2midi(image_path):\n",
    "    with Image.open(image_path) as image:\n",
    "        im_arr = np.fromstring(image.tobytes(), dtype=np.uint8)\n",
    "        try:\n",
    "            print(image.size[1], image.size[0])\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0]))\n",
    "        except:\n",
    "            im_arr = im_arr.reshape((image.size[1], image.size[0],3))\n",
    "            im_arr = np.dot(im_arr, [0.33, 0.33, 0.33])\n",
    "\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "\n",
    "    prev_notes = updateNotes(im_arr.T[0,:],{})\n",
    "    for column in im_arr.T[1:,:]:\n",
    "        notes = column2notes(column)\n",
    "        # pattern is a chord\n",
    "        notes_in_chord = notes\n",
    "        old_notes = prev_notes.keys()\n",
    "        for old_note in old_notes:\n",
    "            if not old_note in notes_in_chord:\n",
    "                new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                if offset - prev_notes[old_note] >= 0:\n",
    "                    new_note.offset = offset - prev_notes[old_note]\n",
    "                    output_notes.append(new_note)\n",
    "                elif offset == 0:\n",
    "                    new_note.offset = offset\n",
    "                    output_notes.append(new_note)\n",
    "                else:\n",
    "                    print(offset,prev_notes[old_note],old_note)\n",
    "\n",
    "        prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += resolution\n",
    "\n",
    "    for old_note in prev_notes.keys():\n",
    "        new_note = note.Note(old_note,quarterLength=prev_notes[old_note])\n",
    "        new_note.storedInstrument = instrument.Piano()\n",
    "        new_note.offset = offset - prev_notes[old_note]\n",
    "\n",
    "        output_notes.append(new_note)\n",
    "\n",
    "    prev_notes = updateNotes(notes_in_chord,prev_notes)\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    name = image_path\n",
    "    name.replace(\".png\",\".mid\")\n",
    "    print(name)\n",
    "\n",
    "    midi_stream.write('midi', 'composition.mid')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x22904b2a700>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiVUlEQVR4nO3dfXRU9bno8e8zySSTEEiAaBCCBJoDVlhCLS1Q9WirIFqPoMejtsrloC29Wq2t+MapXS6P5xbx7arnXBUW9JR6qK1arG9VW3yDVQQFjUJAMQKpCYEQiUlIyCSZee4fM6EJmSSTzOyZSfbzWeu3MrPffs/sPfNk799++YmqYoxxL0+yAzDGJJclAWNczpKAMS5nScAYl7MkYIzLWRIwxuUcSwIiMldEPhGRMhG5w6l6jDGxESeuExCRNGA3MBuoAN4DvqeqO+NemTEmJukOLfebQJmq7gEQkd8B84CISUBE7IolY5xXo6onHD/QqcOBMcDnHd5XhIcdIyKLRWSriGx1KAZjTGflkQY6tSfQK1VdCawE2xMwJpmcSgKVwNgO7wvDw1LKN7/5TRYtWgRAY2Mj9957LzU1NY7WeeaZZ3LVVVexYsUKSkpKoppHRLjpppsYPnw4y5cvp6mpydEYE2nKlClcf/31PPPMM7z55pvJDqeTUaNGcfvtt+Pz+QCi3mZz585l3rx5AFRXV0e1zbxeL0uWLEFEeOCBB2htbe122gULFjBt2jSWL19OXl4eN910Ey+++CKvvvpq9B+uI1WNeyGUXPYA44EM4ENgcg/TazLKFVdcoQ0NDdrQ0KDl5eVaVFTkeJ2LFi3S+vp6nTdvXtTzeDweffHFF7WkpETz8vKSsq6cKnPmzNG6ujq97rrrkh7L8WXSpEm6f/9+bWho6NM2W7JkybHvVbTbzOfz6dtvv60bN25Un8/X47SrV6/W2tpaLS4u1jPPPFNra2v11ltvjSa2rZF+f46cHQAQkQuBh4E04Feq+n96mNaZIHqRm5vLmDGhpopAIMCePXt6zMDxkJeXx6hRo6isrKShoSHq+caNG4fX62XPnj0Eg0EHI0ysnJwcCgsLqa6u5vDhw8kOp5OMjAzGjx9PWloawWAw6m02cuRICgoKAGhpaYlqm4kI48aNA6C8vJyefperV6/m0ksv5Rvf+Ab79+/n5JNPpqamJpq92G2qOr3LUCf2BPqx55DQDJ+ZmakzZszQiRMnOl6XiOiUKVN02rRpmpaWlvT/blZSb5sVFRXpzJkzNScnp8fp8vPz9YwzztAXX3xRGxoa9Morr9QpU6b0pa6IewJJTwDJSAJFRUVaVVWlv/71rx2vKz09Xd944w398MMPdejQoUn/gltJvW22fPlyra+v19NPP73H6a644gptaWnRQCCgqqqtra365z//uS+JKmISSNrZgWSqq6vj4YcfZvfu3Y7XFQwGefLJJxkyZAh+v9/x+kzsEr3N3njjDY4cOcKBAwd6nK60tJRly5Z1GrZ3796YDw8daxPoUxBJahMQEdLS0gBQVQKBQMLqDAQCPR73mdSR6G2Wnp5OMBh0ou0nYpuAq28gOu+881i/fj3r16/nueeeY/To0Y7XedFFF7F+/XrOOussx+sy8ZHIbVZcXMzLL7/Mj370I8fraufKw4F2WVlZjBo1CgCfz3dsr8BJ2dnZFBQUHDv3bFJfIrdZRkYGBQUF5ObmOl5XO1cfDni9XrKzs4HQ4cCRI0ccP/2WkZFBVlYWjY2NtLW1OVqXiY9EbjOPx0NOTg4tLS00NzfHe/ERDwdcnQSMcRlrEzDGdGVJwBiXsyRgjMtZEjDG5SwJGONylgSMcTlLAsa4nCUBY1zOkoAxLmdJwBiXsyRgjMtZEjDG5SwJGONylgSMcTlLAsa4nCUBY1zOkoAxLmdJwBiX63cSEJGxIvKmiOwUkVIRuSk8fISI/EVEPg3/HR6/cI0x8RbLnkAbsERVTwVmAj8WkVOBO4DXVfUfgNfD740xKarfSUBVq1T1/fDrBmAXMAaYB6wJT7YGmB9jjMYYB8Wl3wERKQK+BmwBClS1KjzqAFDQzTyLgcXxqN8Y038xNwyKSA7wB+CnqlrfcZyGnmce8XHiqrpSVadH7CrZGJMwMSUBEfESSgBrVXVdePBBETkpPP4koDq2EI0xTorl7IAAq4FdqvpQh1EvAAvDrxcCz/c/PGOM0/rdA5GInAlsBLYD7X13/RuhdoGngZOBcuByVT3cy7KsByJjnGfdkBnjctYNmTGmK0sCxricJQFjXM6SgDEuZ0nAGJezJGCMy1kSMMblLAkY43KWBIxxOUsCxricJQFjXM6SgDEuZ0nAGJezJGCMy8XlGYOpID09ndBzTnrW1tZGKtw+bUyqGBRJYPjw4axatYoTTzyxx+lUlVtuuYV33303QZEZk/oGRRIQEXJzcxkxYkSP0wWDQdLTB8VHNiZuBsWThUSEIUOGRHU40NTURCAQiKU6YwaqiE8WGhT/FlWVI0eOJDsMY5LK4/Ewb948vF4vzz33HBMnTuSss87i1VdfZd++fd3PqKpJL4T6JrBixUoMxev16qZNm3T79u2ak5OjP/7xjzUYDOr8+fPbp9ka6fc3KA4HjDGhw+Kzzz6b9PR03nrrLcaNG8e0adN455132L9/P9jTho1xPXvasDGmq0HRMJiqJk2axCmnnJLQOnfs2MFnn33maB0+n4+zzz4bn8/naD092bZtGxUVFUmrf1BJdqPgYG4YvPvuuzXRlixZ4vjnGj16tFZWVib8s3W0YMGCpG/fAVgiNgzGvCcgImnAVqBSVS8SkfHA74CRwDZggaq2xFrPQPTyyy9TXZ3Y/lj/+te/Ol5HXV0dd955J9nZ2Y7X1R276jN+Ym4YFJGbgenAsHASeBpYp6q/E5EngA9V9fFelhFbEMaYaMS/YVBECoHvAqvC7wX4DvBseJI1wPxY6jDGOCvWswMPA7fx916JRwJfqmpb+H0FMCbSjCKyWES2isjWGGMwxsSg30lARC4CqlV1W3/mV9WVqjo90u6JMSZxYmkYPAO4WEQuBHzAMOARIE9E0sN7A4VAZexhGmOc0u89AVVdqqqFqloEXAm8oapXAW8Cl4UnWwg8H3OUxhjHOHHF4O3AzSJSRqiNYLUDdRhj4sTuHTDGPezeAWNMV5YEjHE5SwLGuJwlAWNczpKAMS5nScAYl0uZh4oUFBQwbdq0ZIfRZwcPHqSkpITJkyczatQoNm/eTGNjY7LDMuaYadOmUVBQwGuvvRZ5gkgPGUh0AfSSSy7RQCCgwWBwQJXf//73CuiKFSu0trZWJ02alOwHR1ix0qmsW7dOg8Gg4tRDReJl+/bt3HbbbckOo892794NwLPPPsv27dsT/hARY3qzZs2aHh82Y1cMpgCPx0NGRkanYcFgkJaWFtLT03vsOk1VaWlpSWonq16vl7S0NMeW39LSQjAY7H1C05vB2wPRQHfWWWfx4IMPdupGbfv27fzwhz/k6quv5oYbbuh23i+//JKrr76aqqqqRIQa0S233MJll13W+4T9EAwGufHGG9m8ebMjyzd2dsAY17PDgRTg8XjIzMzsNCwYDOL3+0lPT8fr9XY7r6ri9/uTfjjgZG/Pfr/fDgfiww4HUlUwGOTo0aMRx7W1tdHW1hZxXKpobW2ltbU12WGYfrLDAWNczpKAMS5nScAYl7MkYIzLWcOgMQPMjBkzmDBhQp/ne+qppyIOt1OExgwwq1ev5pprrunzfCJipwiNGQx+9atfsXHjxrgtz/YEjHEPe9qwMaYrSwLGuJwlAWNcLqYkICJ5IvKsiHwsIrtEZJaIjBCRv4jIp+G/w+MVrDEm/mJqGBSRNcBGVV0lIhlANvBvwGFVvVdE7gCGq+rtvSzHdQ2D6enpeDzd52BVtZty4ijS+m5ra0u5uxNFpMe7RmPR0tISsWGw30lARHKBEmCCdliIiHwCnKOqVSJyEvCWqk7qZVmuSwK//OUv+fa3v93t+B07dnD99ddbIoiT+++/nzPPPLPTsGXLlvHCCy8kKaLIJk2axBNPPIHP54v7smfNmhX36wTGA4eA/xaRqcA24CagQFXbH3NzACiINLOILAYWx1D/gObz+cjJyel2fHZ2dgKjGfwirW+n/uPGQkQYOnRol+dLOFpnDHsC04HNwBmqukVEHgHqgRtVNa/DdLWq2mO7gBv3BDIzM3t8EEdPzxgwfefz+bo8B9Hv96fcsxo8Hg9ZWVmOLLuxsTHuewIVQIWqbgm/fxa4AzgoIid1OBywx+9G4Pf78fv9yQ7DNZqbm5MdQlSCwWDC+63o99kBVT0AfC4i7cf75wI7gReAheFhC4HnY4rQGOOoWO8duBFYGz4zsAdYRCixPC0i1wLlwOUx1jFgfe973+OKK67odbotW7awbNkyILTbunz5csaNGweE+jP4n//5H0fjHDJkCA888AA1NTXcddddKddibpwVUxJQ1RKgyzEGob2CuMvPz4+6wURVOXToUFSt68OHD4+qIe7IkSPU1dUxcuRIvF4v1dXVPf5gRo8ezde//vWI4/Lz88nIyKC6upqmpibGjBkDQFZWFnPmzOErX/kKhw4dSsijttPS0pgyZQpVVVWdHntuBp4TTjihSx8W7SorKyMOHzA3EKWlpfH0008za9asqJbZ3NzMP/3TP1FaWtrrtI8++mhUz81ftWoVd911F2vWrOHUU0/lggsu4NChQ91On5OTw9ChQyOOW7lyJTNmzGDu3LlMnDiRhx56CAi1Dufn5/PRRx9x6aWXcvjwYRoaGnqNLRbtdQYCAQ4fPuxoXcY5Xq+XdevWdfuPZ/To0QP7VmJVpbS0NOr/VH6/P+oGlrKysqj+4+7duxdVZdeuXTQ3N9PS0tLj9EeOHOHIkSMRx23YsIHq6mrKy8vxeDy88847nT7b7t27qaysTEjrdftekxnYVJUdO3b0+dqSAbMnYIyJmd1KbIzpasAcDhzP6/X26aqqlpYWWlpayMrK6lPnmU1NTUDfruALBAIcPXqUjIyMbhtpIvH7/bS2tpKdnd3jfQXtmpubjx0upKWl9ekik7a2Npqbm8nMzOzxyrlgMHhsHZjU0L7NGhsbu/Q8Fem70/F7EsmATQIXX3wx//7v/x719KtWreKRRx7h0Ucf5Vvf+lZU87S0tLBgwQJaW1v57W9/G/X13Fu3buWaa65h8eLFXHfddVHH+Mtf/pJ169axdu1aJk6c2Ov0t912Gy+//DIAs2bN4vHHH48qeQD86U9/4tZbb+XOO+/k0ksv7Xa6Tz/9lO9///uWCFLInXfeyezZs7niiisoLy8/Ntzr9bJq1SqmTp3aafqf/OQnvP76690ub8AmAb/f36eW7ObmZlSVhoaGqOdrbW091g1YbW1t1Hse9fX1ABw9erRfMdbX10c1X8eGydbWVmpra6NuOG1vsGxsbOyxrvr6+qT2c2i6amxspLa2lkAg0Gl4d9+d3q5MHbANgx6Pp0+79YFAgGAwSHp6ep/OhbfvRvWlw01Vpa2tzfEY29rajv1ARaRPMQaDQQKBAGlpab3e0pxq19e7Xfs2i3QWINJ3p8P3ZGCfIjxeMBjs15Vt/f1C9+eW3kTG2N/nDwQCgS7/UQaaCRMmcNVVVzl2odO2bduOHXYlQ25uLj/84Q+PtUu98MILlJSUdJnO4/GwYMECxo4dG3E53R4+q2rSC6BWrPS3nHvuuer3+7W1tTWupa2tTVVVn3jiiW7r9ng8mp6e7miZMGGCHjp0SIPBoLa2tuq1114bcbrs7GzdvHmzqmrEzwNsjfT7G7B7Asa0e//995k9e3bc9wSKiop47LHHepzmhhtu6LFhNR58Ph+5ubm88cYb3HPPPcybN4/169d3mU5E+OpXv8revXu5/vrro74V3ZKAGfBqa2vZsGFD3JdbUVHBrl27OHjwYLfTDBs2jFGjRsW97uPt2bOHkpIS3n77bebMmdNtnVVVVezevZsNGzZEfUZnwDYMGuM0j8dDTk4Ora2t3f5X9fl8CXsKUEtLC0ePHiUrK6vH608CgUB3l6sPvIbBgoICLrzwwqjPfZuQQCDASy+9RE1NDQBTpkxhxowZMS2ztLQ0IXc09kVmZibz5s3r9iYtJzQ1NfH8888f+y/b3Nyc8AeWHD16NGJS8ng8fPe73+XEE0+MON/q1asjLzDZjYI9NQyeccYZ2tLSoqZvjh49ql//+tePrcef/exnMS/zP//zP5PeAHh8GTFihJaVlcVhjUWvqqpKCwsLk/7ZIxWv16ubNm3qNnYGYsPgJ598wve//33bE+ijQCDAnj17jr1/+eWXu72XPFplZWWxhhV3R44c4cYbb0zonkBzczNffPFFwurri0AgwC9+8QtGjhzZp/msTcD0SW5ublyPgf1+P3V1deTk5JCVlUVtba1dnOScgdcmYFLP/fffz/nnnx+35b355pssWrSIm2++mauuuopLLrmEnTt3xm35pneWBEyflJeX89FHH8Vtee0Patm/fz87duywG5WSwA4HTJ/F86Kcjt8/EbGblZxlhwMmPpz6oVoCSA5rdjfG5SwJGONylgSMcTlLAsa4XExJQER+JiKlIrJDRJ4SEZ+IjBeRLSJSJiK/D3dRZoxJUf1OAiIyBvgJMF1VpwBpwJXAcuD/qmoxUAtcG49AjTHOiPVwIB3IEpF0IBuoAr5DqJtygDXA/BjrMMY4KJauySuBB4C/Efrx1wHbgC9Vtf3i7wpgTKT5RWSxiGwVka39jcEYE7tYDgeGA/OA8cBoYAgwN9r5VXWlqk6PdAWTMSZxYjkcOA/Yq6qHVLUVWAecAeSFDw8ACoHY7mE1xjgqliTwN2CmiGRL6GLyc4GdwJtAez/fC4HnYwvRGOOkWNoEthBqAHwf2B5e1krgduBmESkDRgLdPNPIGJMK7C5CY9zDuiY3xnRlScAYl7MkYIzLWRI4TnFxMcuWLeOcc84hPT2dG264gZ/+9Kd4vd641zV06FCWLl3KwoULAbj44ou55557HOnRRkRYtGgRd9xxB0OGDGHq1KksX76c6dOn4/P5uPXWW1m8eLEjnXrm5+dz991388///M9xX/bxnN5mg1Kk55AnupACz2xvL+eee642NjbqLbfcopmZmbpx40Z97733NDs7O+51FRQU6GeffabPPPOMAvrQQw/pF198oVOmTIl7XSKizz//vO7evVvz8/P18ssv1+bmZl24cKHm5eXp9u3b9bXXXtO0tLS4111cXKwHDx7Uxx9/3PHt5/Q2G+AlYr8DdnbgOMOGDWPixIlUVlZy4MABvvrVr+LxeNi5c2e/uhnvidfrZfLkyRw5coSysjLGjRtHfn4+O3fujLozyb6YOHEiWVlZlJaWMmzYMIqLi9mzZw+1tbVMnjyZlpYWPv7447jX6/P5mDx5Ml988QX79u2L+/I7au+U06ltNsBFPDtgScAY97BThMaYriwJGONylgSMcTlLAsa4nCUBY1zOkoAxLmfdkA1gM2bMYNy4cQAcOHCADRs2JDmi+Bg+fDjf+c53SEtLQ1XZsGEDBw8eTHZYg1eyrxZMtSsGB1JZu3attnvllVfU4/EkPaZ4lOnTp+vRo0dVVTUQCOicOXOSHtMgKRGvGLQ9gQFs1apVvPXWWwBUVFQMmqvjysvLuf7660lPT0dVKS0tTXZIg5pdMWiMe9gVg8aYrlLmcGDkyJFMnjy507C6ujo++ugjxo4dS1FRUUzL/9vf/ub4zSux+spXvsKoUaMoKSmhsbEx2eHETVZWFl/72teorq6mrKyMU045hby8PD744AP8fn+38xUWFlJUVERpaSm1tbVR1SUiTJ06FY/HQ0lJyaA5RHJUshsF2xsG58+fr62trZ3K22+/rV6vV5cuXdplXF/LsmXLkt0o02t5+OGH9csvv3TkVuJkluLiYq2pqdEVK1YohBo0KysrdezYsT3Od8stt6jf79fZs2dHXVdmZqZu2rRJt23bZrcSdy2p3TD48ccfc88993Qa9vnnnxMIBNi4cWOXcX3117/+Nab5E+HVV1/lwIEDVFdXJzuUuKqtreW+++5j165dAKxbt47333+furq6HufbtGkT//Ef/8Fnn30WdV1tbW2sXr2a9PR0WltbY4rbLaxh0Bj3sIZBY0xXKXM40JHH46GoqIhgMMi+ffvIz8/nxBNPBMDv97N3795B1eCTk5NDYWEhHk/PObmlpYU9e/bE5bMPGzaMwsJC9u/fz5dfftlp3AknnMDIkSMpLy+P+glH7dvM5/P1K54DBw5w+PDhqKcfPXo0eXl5UU0bDAapqKigubmZCRMm0NTUREVFRb/ibNdxmwWDQfbu3dtjI2dKS3ajYKQrBnNycnTLli362muvqdfr1dtuu03r6+u1vr5et23bpsOGDUt2A0tcywUXXKB1dXXHPmN35YMPPtC8vLy41HnZZZdpfX29LliwoMu4X/ziF1pTU6PTp0+Pennt26y3z9Bdue666/oU/4oVK6Jedl1dnc6dO1fHjBmjZWVlumbNmrhus6qqKp08eXLSv0dRlP41DIrIr4CLgGpVnRIeNgL4PVAE7AMuV9XacJ+EjwAXAk3Av6rq+73VcbzW1lZeeukljh49SjAYZPv27axduxaAgwcP0tLS0tdFprTKykrWrl3b65N+q6ur4/bZ9+3bx9q1ayM2un344Yc89dRT1NTURL289m32/vt93twAfX624aZNm6LeI1JVKioqaGpq4g9/+ANlZWX9CbGTjtvM7/dHfQozJUXxX/ofgdOBHR2G3QfcEX59B7A8/PpC4BVAgJnAFrt3wIqVlCkR9wR6bRhU1Q3A8Qdr84A14ddrgPkdhv8mfE/LZkLdlJ/UWx3GmOTp79mBAlWtCr8+ABSEX48BPu8wXUV4WBcislhEtorI1n7GYIyJg5jPDqiq9uc8v6quJNSVuV0nYEwS9TcJHBSRk1S1Kry7336JWyUwtsN0heFhKSU7O5uzzz6bjIwMALZt2xbzKaNkO/HEE5k5cyalpaXs3buXs846C4CNGzcOqtOpg0n7NovUIFxWVpa4W6ijbLgronPD4P10bhi8L/z6u3RuGHw3FRsGJ0yYoDU1Ndou0mmygVbOP/98bWtr0yVLlqjP59P33ntPt27dqllZWUmPzUrP2yySBx980Ik6+32K8CngHCBfRCqAu4B7gadF5FqgHLg8PPmfCJ0hKCN0inBRb8tvN3XqVH7wgx8AoQuCHnzwQaqqqnqZq39qamq4/fbbj13Y8u677zpSTyLt2rWLG2+8kXfeeYfW1lbuu+8+RGTQnU4dTNq3WaSLxEpKShIXSDIuDoq0J3DxxRdrQ0ODNjQ0aFVVlZ5yyilJz9RWrAyyktodkg4bNoyTTz4ZAFWlrKxs4F6GaUxqsg5JjXE5u4vQGNOVJQFjXG5QJwGPx9Pr7bnGvTweD2lpacfep6Wl9XoT12A0aH8hmZmZPPHEE/zXf/0XXq832eGYFHTTTTfxxz/+kbFjx3LaaafxyiuvcPXVVyc7rIRLyYeKxIOIMGrUKNra2lyZ3U3vRowYQWFhIV6vl4yMDMaOHUtubm6yw0q4QX12YOjQoQA0NDQ4sXgzwGVnZ+P1emloaMDj8ZCTk0NzczPNzc3JDs0pdorQGJezU4TGmK4sCZgu/uVf/oU1a9ZQXFzc72XMnz+f3/zmN5xyyildxt1www089thjjBw5MpYwE+bb3/42Tz75JNOnd/knOihYEjBdFBcXc95550X9NN9Ixo8fz+zZsxkxYkSXcaeddhrnnHNOv59MnGhjx47l/PPPZ9SoUckOxRHWJmC6yMvLIzc3lwMHDvT7/o3c3Fzy8vIiLuOEE07A5/Oxf/9+AoFAPEJ2VE5ODvn5+VRXV9PU1JTscGIxcBoG09LSmDlzJjk5OV2mbWxsZPPmzbS1tUW17GHDhjFjxgzKy8vZvXt3fAI2ZmCKmASSfhtxpIeK5OTk6Pbt2zUYDHYpu3bt0tzc3Khvn5w+fbo2NTXpvffem+zbOK1YSXZJ7Q5JO/L7/TzwwAPk5+d3GXf48OGoe8WBUKemS5cuZdu2bfEM0ZhBIyUPB4wxjrDrBIwxXVkSMMblLAkY43KWBIxxOUsCxricJQFjXM6SgDEuZ0nAGJfrNQmIyK9EpFpEdnQYdr+IfCwiH4nIcyKS12HcUhEpE5FPROR8h+I2xsRJNHsCvwbmHjfsL8AUVT0N2A0sBRCRU4ErgcnheR4TkTSMMSmr1ySgqhuAw8cN+7Oqtt/Gt5lQF+QA84DfqapfVfcS6pj0m3GM1xgTZ/FoE7iGUHfkAGOAzzuMqwgP60JEFovIVhHZGocYjDH9FNNdhCLyc6ANWNvXeVV1JbAyvBy7gciYJOl3EhCRfwUuAs7Vv9+KWAmM7TBZYXiYMSZF9etwQETmArcBF6tqx+ctvQBcKSKZIjIe+Afg3djDNMY4pdc9ARF5CjgHyBeRCuAuQmcDMoG/hHv32ayq/1tVS0XkaWAnocOEH6tq6j9EzhgXs4eKGOMe9lARY0xXlgSMcTlLAsa4nCUBY1zOkoAxLmdJwBiXsyRgjMulSg9ENUBj+G+y5WNxdGRxdDaQ4xgXaWBKXCwEICJbI3aWaHFYHBaHo3HY4YAxLmdJwBiXS6UksDLZAYRZHJ1ZHJ0NujhSpk3AGJMcqbQnYIxJAksCxrhcSiQBEZkb7qegTETuSFCdY0XkTRHZKSKlInJTePgIEfmLiHwa/js8QfGkicgHIvJS+P14EdkSXie/F5GMBMSQJyLPhvuU2CUis5KxPkTkZ+FtskNEnhIRX6LWRzf9bERcBxLyaDimj0TkdIfjcKa/D1VNagHSgM+ACUAG8CFwagLqPQk4Pfx6KKH+E04F7gPuCA+/A1ieoPVwM/Bb4KXw+6eBK8OvnwCuS0AMa4AfhF9nAHmJXh+Enk69F8jqsB7+NVHrA/hH4HRgR4dhEdcBcCGhJ20LMBPY4nAcc4D08OvlHeI4Nfy7yQTGh39PaVHX5fQXK4oPOwt4rcP7pcDSJMTxPDAb+AQ4KTzsJOCTBNRdCLwOfAd4KfylqumwwTutI4diyA3/+OS44QldH/z9sfUjCF3R+hJwfiLXB1B03I8v4joAVgDfizSdE3EcN+4SYG34daffDPAaMCvaelLhcCDqvgqcIiJFwNeALUCBqlaFRx0AChIQwsOEHtwaDL8fCXypf+/gJRHrZDxwCPjv8GHJKhEZQoLXh6pWAg8AfwOqgDpgG4lfHx11tw6S+d3tV38fkaRCEkgqEckB/gD8VFXrO47TUFp19ByqiFwEVKvqNifriUI6od3Px1X1a4Tu5ejUPpOg9TGcUE9W44HRwBC6doOXNIlYB72Jpb+PSFIhCSStrwIR8RJKAGtVdV148EEROSk8/iSg2uEwzgAuFpF9wO8IHRI8AuSJSPsNXolYJxVAhapuCb9/llBSSPT6OA/Yq6qHVLUVWEdoHSV6fXTU3TpI+He3Q38fV4UTUsxxpEISeA/4h3DrbwahDk1fcLpSCT0rfTWwS1Uf6jDqBWBh+PVCQm0FjlHVpapaqKpFhD77G6p6FfAmcFkC4zgAfC4ik8KDziX06PiErg9ChwEzRSQ7vI3a40jo+jhOd+vgBeB/hc8SzATqOhw2xJ1j/X042cjThwaQCwm1zn8G/DxBdZ5JaLfuI6AkXC4kdDz+OvApsB4YkcD1cA5/PzswIbwhy4BngMwE1D8N2BpeJ38EhidjfQB3Ax8DO4AnCbV6J2R9AE8RaotoJbR3dG1364BQA+7/C39vtwPTHY6jjNCxf/v39YkO0/88HMcnwAV9qcsuGzbG5VLhcMAYk0SWBIxxOUsCxricJQFjXM6SgDEuZ0nAGJezJGCMy/1/jmuJScWYd+sAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = torch.randn(1, latent_dim, 1, 1, device=device)\n",
    "THRESHOLD = 0.5\n",
    "fake = generator(noise).detach().cpu().numpy()\n",
    "fake = fake.reshape((128, 128))\n",
    "fake[fake >= THRESHOLD] = 1\n",
    "fake[fake < THRESHOLD] = 0\n",
    "# fake = fake.astype(np.uint8)\n",
    "plt.imshow(fake, cmap='gray')\n",
    "# fake.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 128\n",
      "composition.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mateu\\AppData\\Local\\Temp/ipykernel_12936/2744369202.py:3: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  im_arr = np.fromstring(image.tobytes(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "array = np.array(fake, dtype = np.uint8)\n",
    "array*= 255\n",
    "new_image = Image.fromarray(array,'L')\n",
    "new_image = new_image.save('composition.png')\n",
    "image2midi('composition.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Useful functions for CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def conv_size(input_size, padding, kernel_size, stride):\n",
    "    return (input_size + 2 * padding - (kernel_size - 1) - 1) / stride + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def transpose_conv_size(input_size, padding, kernel_size, stride):\n",
    "    return (input_size - 1) * stride - 2 * padding + kernel_size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "384.0"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 384\n",
    "stride = 1\n",
    "padding = 1\n",
    "kernel_size = 3\n",
    "# transpose_conv_size(input_size=input_size, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "conv_size(input_size=input_size, padding=padding, kernel_size=kernel_size, stride=stride)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_size(input_size=input_size, padding=padding, kernel_size=kernel_size, stride=stride)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transpose_conv_size(input_size=input_size, padding=padding, kernel_size=kernel_size, stride=stride)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test .bmp samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pypianoroll"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'train_dataset_lpd/train/1772_train.bmp'\n",
    "img = Image.open(IMAGE_PATH)\n",
    "array = np.array(img)\n",
    "\n",
    "pr = pypianoroll.Multitrack()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pr.append(pypianoroll.BinaryTrack(pianoroll=array.transpose()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pr.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pr.write('test.midi')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}