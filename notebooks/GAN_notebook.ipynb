{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.constants import LATENT_DIM, BATCH_SIZE, NUMBER_OF_PITCHES, LOWEST_PITCH, MUSIC_LENGTH, MUSIC_LENGTH, LPD_PATH, MAESTRO_PATH, LPD_FILE_EXTENSION, \\\n",
    "    MAESTRO_FILE_EXTENSION, NUM_EPOCHS, INFO_INTERVAL_EPOCHS\n",
    "\n",
    "from src.utils import array_to_midi, get_device, show_learning_process, write_model_params_to_tensorboard, write_models_architecture_to_tensorboard, \\\n",
    "    write_losses_to_tensorboard, write_samples, save_models, generate_random_midi_array, array_to_midi\n",
    "\n",
    "from src.data_preparation import prepare_data\n",
    "\n",
    "from src.train_eval import train_one_step, Metrics\n",
    "\n",
    "from src.models import Generator, Discriminator, SequenceBarGenerator, TemporalVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pianoroll_idx -> maestro has index 0 and LPD has index 1 for piano data\n",
    "\n",
    "data_stacked = prepare_data(\n",
    "    file_path = MAESTRO_PATH,\n",
    "    file_extension=MAESTRO_FILE_EXTENSION,\n",
    "    length=MUSIC_LENGTH,\n",
    "    music_info_threshold = 0.02,\n",
    "    pianoroll_idx=0,\n",
    "    do_filtration=True\n",
    ")\n",
    "data_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'../data/data_maestro_192_0.02.npy', data_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lpd = np.load(f'../data/data_192_0.04.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_maestro = np.load(f'../data/data_maestro_192_0.04.npy')\n",
    "# data_stacked = np.load(f'../data/data_maestro_192_0.04.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_stacked = np.concatenate((data_lpd, data_maestro), axis=0)\n",
    "# data_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.as_tensor(data_stacked, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(training_data)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models, optimizers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorboard writer instance\n",
    "tensorboard_writer = SummaryWriter()\n",
    "\n",
    "# Create models\n",
    "vectors_model = TemporalVectors(latent_vector_size=LATENT_DIM, hidden_size=LATENT_DIM, num_layers=2, sequence_length=3, device=device)\n",
    "bar_generator = Generator()\n",
    "generator = SequenceBarGenerator(vectors_generator=vectors_model, bar_generator=bar_generator)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# generator = torch.load('generators/99_generator.pt')\n",
    "# discriminator = torch.load('discriminators/99_discriminator.pt')\n",
    "\n",
    "discriminator = discriminator.to(device)\n",
    "generator = generator.to(device)\n",
    "\n",
    "# Create optimizers\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001,  betas=(0.5, 0.9))\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.9))\n",
    "\n",
    "# FOR ONE BAR\n",
    "# sample_latent = torch.randn(8, LATENT_DIM, 1, 1).to(device)\n",
    "\n",
    "# FOR SEQUENCE\n",
    "sample_latent = torch.randn(1, 1, LATENT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_models_architecture_to_tensorboard(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    real_images_sample=training_data[0].reshape((1, 1, MUSIC_LENGTH, NUMBER_OF_PITCHES)).to(device),\n",
    "    noise=torch.randn(1, 1, LATENT_DIM).to(device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_evaluation = pd.DataFrame()\n",
    "metrics = Metrics(bar_generator=generator, resolution=6, threshold=0.9, probe=50, device=device)\n",
    "\n",
    "step = 0\n",
    "\n",
    "history_samples = {}\n",
    "discriminator_losses = []\n",
    "generator_losses = []\n",
    "\n",
    "generator.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for real_samples in data_loader:\n",
    "        d_loss, g_loss = train_one_step(\n",
    "            discriminator_optimizer=discriminator_optimizer,\n",
    "            generator_optimizer=generator_optimizer,\n",
    "            discriminator=discriminator,\n",
    "            generator=generator,\n",
    "            real_samples=real_samples[0].reshape(-1, 1, MUSIC_LENGTH, NUMBER_OF_PITCHES), \n",
    "            device=device\n",
    "         )\n",
    "        step += 1\n",
    "\n",
    "    if epoch % INFO_INTERVAL_EPOCHS == 0:\n",
    "        # Get generated samples\n",
    "        print(f'EPOCH [{epoch}] | STEP [{step}] ---> Critic loss: {d_loss:.4f}  Generator loss: {g_loss:.4f}')\n",
    "        generator.eval()\n",
    "        samples = generator(sample_latent).cpu().detach().numpy()\n",
    "        history_samples[step] = samples\n",
    "        generator.train()\n",
    "\n",
    "        d_loss = d_loss.detach().cpu()\n",
    "        g_loss = g_loss.detach().cpu()\n",
    "        discriminator_losses.append(d_loss)\n",
    "        generator_losses.append(g_loss)\n",
    "\n",
    "        write_model_params_to_tensorboard(tb_writer=tensorboard_writer, model=generator, epoch=epoch, prefix='generator_')\n",
    "        write_model_params_to_tensorboard(tb_writer=tensorboard_writer, model=discriminator, epoch=epoch, prefix='discriminator_')\n",
    "\n",
    "        write_losses_to_tensorboard(writer=tensorboard_writer, critic_loss=d_loss, generator_loss=g_loss, step=epoch)\n",
    "        \n",
    "        save_models(discriminator=discriminator, generator=generator, prefix=f'{epoch}_epoch')\n",
    "        write_samples(generator=generator, device=device, name=f'{epoch}_epoch', threshold=0.5)\n",
    "\n",
    "        next_epoch_metrics = metrics.create_metrics_df()\n",
    "        training_evaluation = pd.concat([next_epoch_metrics, training_evaluation], ignore_index=True)\n",
    "        training_evaluation.to_csv('../reports/metrics_eval.csv', index_label='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator losses')\n",
    "plt.plot(range(len(generator_losses)), generator_losses)\n",
    "plt.savefig(f'../reports/figures/generator_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Discriminator losses')\n",
    "plt.plot(range(len(discriminator_losses)), discriminator_losses)\n",
    "plt.savefig(f'../reports/figures/discriminator_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_learning_process(list(history_samples.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.bar_generator.vectors_generator.sequence_length=3\n",
    "array_example = metrics.generate_random_midi_array()\n",
    "array_to_midi(music_array=array_example, midi_path='test.midi', plot=True, resolution=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_evaluation.columns:\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title(i)\n",
    "    plt.plot(training_evaluation[i])\n",
    "    plt.savefig(f'../reports/figures/{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = muspy.read('../samples/midi/')\n",
    "muspy.outputs.write_audio(path=output_path, music=music)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd73e498ae4434ec3c1163eca4f1be14de616e2816aba7972f437bb9000963c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
